ğŸ“Š Telco Churn â€” End-to-End MLOps Pipeline
ğŸ¯ Project Overview

This project implements a production-ready MLOps pipeline for customer churn prediction, with a strong focus on business impact, automation, and usability by non-technical teams.
The goal is not only to train a churn model, but to cover the entire machine learning lifecycle, from data preparation to deployment, monitoring, and automated retraining.

ğŸ§  Business Problem

In highly competitive B2B and B2C markets, retaining high-value customers is critical.
However, commercial teams often lack actionable prioritization tools to decide which customers to focus on first.

This project provides:
- a churn prediction model
- a REST API for scoring customers
- a business-oriented UI to prioritize retention actions

ğŸ§± Project Architecture

The pipeline covers the full MLOps lifecycle:
- Data preparation & feature engineering
- Model training & evaluation
- Experiment tracking & versioning
- REST API deployment
- Business-oriented web UI
- Monitoring & data drift detection
- Automated retraining
- Model promotion & rollback strategy

ğŸ“ Repository Structure
churn-mlops-telco/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                 # FastAPI inference service
â”‚   â”œâ”€â”€ app_web.py           # Streamlit business UI
â”‚   â”œâ”€â”€ retraining/          # Automated retraining logic
â”‚   â””â”€â”€ monitoring/          # Drift detection (Evidently)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ production_pipeline.joblib   # Single production model
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ new/                 # Placeholder for new incoming data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ mlflow/
â”‚   â””â”€â”€ test_api/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ retrain.yml          # GitHub Actions retraining workflow
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ run_project.ps1

ğŸ¤– Modeling

Task: Binary classification (churn / non-churn)
Models tested:
Logistic Regression
Random Forest
Gradient Boosting
Final model: Logistic Regression
class_weight="balanced"
Optimized for recall on churn class
Business threshold: 0.40
The final pipeline includes:
preprocessing (ColumnTransformer)
feature engineering
model inference

All serialized into a single pipeline artifact.

ğŸ“ˆ Experiment Tracking & Versioning

MLflow is used for:
- experiment tracking
- metrics logging
- artifact storage
- retraining traceability

Experiments:

- telco-churn-final â€” training
- telco-churn-retraining â€” automated retraining
- telco-churn-prod â€” production monitoring

Only one production model is versioned in the repository:

models/production_pipeline.joblib

ğŸš€ API â€” FastAPI
Endpoints

GET /health
Health check & configuration overview

POST /predict
Predict churn for a single customer (JSON)

POST /predict_csv
Batch scoring via CSV upload

Features

Stateless & scalable API

Business threshold applied server-side

Batch size safety limit

Latency & throughput monitoring

Optional MLflow logging

ğŸ–¥ï¸ Business UI â€” Streamlit

A non-technical, commercial-friendly interface:

CSV upload

Batch scoring via API

Client prioritization

Risk classification:

ğŸ”´ High
ğŸŸ  Medium
ğŸŸ¢ Low

KPI counters

Filtering (high-risk only)

Export only selected customers

ğŸ“Š Monitoring & Drift Detection

Evidently used for data drift detection
- Reference dataset built from training data
- Production batches optionally stored
- Drift reports generated as HTML
- Drift signals used as retraining triggers

ğŸ” Automated Retraining

Retraining is automated using GitHub Actions (lightweight, no infrastructure overhead).

Triggers:

New data detected in data/new/

Data drift detected

Significant metric degradation

Manual trigger (workflow_dispatch)

Workflow:

Retrain model

Log metrics to MLflow

Save candidate model

Promote or rollback based on business rules

â–¶ï¸ Quickstart
1. Install dependencies
pip install -r requirements.txt

2. Start the API
uvicorn src.api.main:app --reload

3. Start the UI
streamlit run src/app_web.py

âš™ï¸ Environment Variables (optional)
API_URL=http://localhost:8000
BUSINESS_THRESHOLD=0.40
MAX_BATCH_ROWS=50000
MLFLOW_TRACKING_URI=file:///path/to/mlruns

âœ… Key Design Choices

Simplicity over over-engineering

No Kubernetes

No Docker (by design)

GitHub Actions instead of Airflow

Single production model

Clear separation between training, inference, and business usage

ğŸ“Œ Final Notes

This project is designed as:

- a realistic production-grade MLOps example
- a portfolio-ready project
- a foundation adaptable to real company data

âœ¨ Status: Production-ready
âœ¨ Focus: Business value + MLOps best practices